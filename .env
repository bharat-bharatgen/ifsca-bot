# this .env used in docker-compose setup

# vLLM Chat Model (GPT-OSS-20B)
VLLM_CHAT_BASE_URL=http://bharat-vllm-gpt-oss:8000/v1
VLLM_CHAT_MODEL=openai/gpt-oss-20b

# vLLM Embedding Model (Qwen3-Embedding)
VLLM_EMBED_BASE_URL=http://bharat-vllm-qwen-embedding:8000/v1
VLLM_EMBED_MODEL=Qwen/Qwen3-Embedding-0.6B

# LightRAG API
LIGHTRAG_BASE_URL=http://bharat-lightrag:9621
LIGHTRAG_QUERY_MODE=hybrid

# Optional: API Keys (if your vLLM instances require them)
VLLM_API_KEY=
LIGHTRAG_API_KEY=

# Langfuse Observability (get keys from http://localhost:3000/settings/api-keys)
LANGFUSE_ENABLED=true
LANGFUSE_BASE_URL=http://bharat-langfuse:3000
LANGFUSE_SECRET_KEY="sk-lf-b6dec041-e5ca-4393-b11c-14f2a15407d0"
LANGFUSE_PUBLIC_KEY="pk-lf-b333b892-b900-4bac-99e6-6a3f1e6db9b1"
SYSTEM_PROMPT_VERSION=v3-doc-priority