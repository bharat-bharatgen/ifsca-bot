# vLLM Chat Model
VLLM_CHAT_BASE_URL=http://localhost:8001/v1
VLLM_CHAT_MODEL=openai/gpt-oss-20b

# vLLM Embedding Model
VLLM_EMBED_BASE_URL=http://localhost:8002/v1
VLLM_EMBED_MODEL=Qwen/Qwen3-Embedding-0.6B

# LightRAG API
LIGHTRAG_BASE_URL=http://localhost:9621
LIGHTRAG_QUERY_MODE=hybrid

# Optional: API Keys
VLLM_API_KEY=
LIGHTRAG_API_KEY=

# Langfuse Observability (LLM Tracing)
LANGFUSE_ENABLED=true
LANGFUSE_BASE_URL=http://localhost:3000
LANGFUSE_PUBLIC_KEY=pk-lf-xxx
LANGFUSE_SECRET_KEY=sk-lf-xxx

# System Prompt Version (see lib/prompts/ for all available versions)
# v1-detailed      = Original detailed prompt with response guidelines
# v2-rag-optimized = RAG-optimized prompt (zero hallucination, strict grounding, required citations)
# Add new prompts in lib/prompts/ and register in lib/prompts/index.ts
SYSTEM_PROMPT_VERSION=v1-detailed

# Reference Data Injection (for improved accuracy)
# Set to "false" to disable all reference data injection
INCLUDE_REFERENCE_DATA=true

# Individual reference data sections (only used if INCLUDE_REFERENCE_DATA=true)
# Set any of these to "false" to exclude that section
INCLUDE_FEE_STRUCTURE=true
INCLUDE_GRANT_MILESTONES=true
INCLUDE_SANDBOX_DEFINITIONS=true
INCLUDE_PERMISSIBLE_EXPENSES=true
